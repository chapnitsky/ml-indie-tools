

<!doctype html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>env_tools &#8212; ml-indie-tools 0.0.4 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bizstyle.css" />
    
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <!--[if lt IE 9]>
    <script src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">ml-indie-tools 0.0.4 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">env_tools</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for env_tools</h1><div class="highlight"><pre>
<span></span><span class="sd">&#39;&#39;&#39;Tools to configure ML environment for Tensorflow, Pytorch or JAX and </span>
<span class="sd">optional notebook/colab environment&#39;&#39;&#39;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">logging</span>

<div class="viewcode-block" id="MLEnv"><a class="viewcode-back" href="../index.html#env_tools.MLEnv">[docs]</a><span class="k">class</span> <span class="nc">MLEnv</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot; Initialize platform and accelerator. </span>
<span class="sd">    </span>
<span class="sd">    This checks initialization and available accelerator hardware for different ml platforms.</span>
<span class="sd">    At return, the following variables are set: `self.is_tensorflow`, `self.is_pytorch`, `self.is_jax`,</span>
<span class="sd">    indicating that the ml environment is available for Tensorflow, Pytorch or JAX respectively if `True`.</span>
<span class="sd">    `self.is_notebook` and `self.is_colab` indicate if the environment is a notebook or colab environment.</span>
<span class="sd">    `self.is_gpu` indicates if the environment is a GPU environment, `self.is_tpu` indicates if the </span>
<span class="sd">    environment is a TPU environment, and `self.is_cpu` that no accelerator is available.</span>
<span class="sd">    </span>
<span class="sd">    The logger `MLEnv` provdides details about the hardware and ml environment.</span>

<span class="sd">    :param platform: Known platforms are: `&#39;tf&#39;` (tensorflow), `&#39;pt&#39;` (pytorch), and `&#39;jax&#39;`</span>
<span class="sd">    :param accelerator: known accelerators are: `&#39;fastest&#39;` (pick best available hardware), `&#39;cpu&#39;`, `&#39;gpu&#39;`, `&#39;tpu&#39;`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">platform</span><span class="o">=</span><span class="s1">&#39;tf&#39;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s1">&#39;fastest&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;MLEnv&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">known_platforms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;tf&#39;</span><span class="p">,</span> <span class="s1">&#39;pt&#39;</span><span class="p">,</span> <span class="s1">&#39;jax&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">known_accelerators</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="s1">&#39;gpu&#39;</span><span class="p">,</span> <span class="s1">&#39;tpu&#39;</span><span class="p">,</span> <span class="s1">&#39;fastest&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">platform</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">known_platforms</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Platform </span><span class="si">{</span><span class="n">platform</span><span class="si">}</span><span class="s2"> is not known, please check spelling.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="n">accelerator</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">known_accelerators</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accelerator </span><span class="si">{</span><span class="n">accelerator</span><span class="si">}</span><span class="s2"> is not known, please check spelling.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">os_type</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#: Operating system type, e.g. `&#39;Linux&#39;`, `&#39;Darwin&#39;`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">py_version</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#: Python version, e.g. `&#39;3.7.3&#39;`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_conda</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if running in a conda environment</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if running on Tensorflow</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tf_version</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#: Tensorflow version, e.g. `&#39;2.7.0&#39;`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_pytorch</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if running on Pytorch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pt_version</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#: Pytorch version, e.g. `&#39;1.6.0&#39;`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_jax</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if running on Jax</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">jax_version</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#: Jax version, e.g. `&#39;0.1.0&#39;`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if no accelerator is available</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if a GPU is is available</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if a TPU is is available</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tpu_type</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#: TPU type, e.g. `&#39;TPU v2&#39;`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gpu_type</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1">#: GPU type, e.g. `&#39;Tesla V100&#39;`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if running in a notebook</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1">#: `True` if running in a colab notebook</span>
        <span class="k">if</span> <span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_version</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
            <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensorflow not available: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">from</span> <span class="nn">tensorflow.python.profiler</span> <span class="kn">import</span> <span class="n">profiler_client</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_prof</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tf_prof</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensorflow version: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;tpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">tpu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">TPUClusterResolver</span><span class="p">()</span>  <span class="c1"># TPU detection</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Running on TPU &#39;</span><span class="p">,</span> <span class="n">tpu</span><span class="o">.</span><span class="n">cluster_spec</span><span class="p">()</span><span class="o">.</span><span class="n">as_dict</span><span class="p">()[</span><span class="s1">&#39;worker&#39;</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                    <span class="n">tpu</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">accelerator</span><span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;No TPU available&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>    
                    <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental_connect_to_cluster</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">tpu</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">initialize_tpu_system</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tpu_strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tpu_num_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tpu_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">worker_devices</span><span class="p">)</span>
                    <span class="n">tpu_profile_service_address</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;COLAB_TPU_ADDR&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;8470&#39;</span><span class="p">,</span> <span class="s1">&#39;8466&#39;</span><span class="p">)</span>
                    <span class="n">tpu_type</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;TPU, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tpu_num_nodes</span><span class="si">}</span><span class="s2"> nodes&quot;</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_prof</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="kn">from</span> <span class="nn">tensorflow.python.profiler</span> <span class="kn">import</span> <span class="n">profiler_client</span>
                        <span class="n">state</span><span class="o">=</span><span class="n">profiler_client</span><span class="o">.</span><span class="n">monitor</span><span class="p">(</span><span class="n">tpu_profile_service_address</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
                        <span class="k">if</span> <span class="s1">&#39;TPU v2&#39;</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
                            <span class="n">tpu_type</span><span class="o">=</span><span class="n">tpu_type</span><span class="o">+</span><span class="s1">&#39;v2 (8GB)&#39;</span>  <span class="c1"># that&#39;s what you currently get on Colab    </span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;You got old TPU v2 which is limited to 8GB Ram.&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tpu_type</span> <span class="o">=</span> <span class="n">tpu_type</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;TPU strategy available&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU not available: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">gpu_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">get_device_details</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])[</span><span class="s1">&#39;device_name&#39;</span><span class="p">]</span>
                        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not get GPU type: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;GPU available&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;No GPU or TPU available, this is going to be very slow!&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;jax&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">jax</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_jax</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">jax_version</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">__version__</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Jax not available&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_jax</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;tpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="kn">import</span> <span class="nn">jax.tools.colab_tpu</span> <span class="k">as</span> <span class="nn">tpu</span>
                        <span class="n">jax</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">colab_tpu</span><span class="o">.</span><span class="n">setup_tpu</span><span class="p">()</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">jd</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JAX TPU detected: </span><span class="si">{</span><span class="n">jd</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;JAX TPU not detected.&quot;</span><span class="p">)</span>
                            <span class="k">return</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">jd</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">gpu_device_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;GTX&#39;</span><span class="p">,</span> <span class="s1">&#39;Nvidia&#39;</span><span class="p">]</span>  <span class="c1"># who knows?</span>
                        <span class="k">for</span> <span class="n">gpu_device_name</span> <span class="ow">in</span> <span class="n">gpu_device_names</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">gpu_device_name</span> <span class="ow">in</span> <span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JAX GPU: </span><span class="si">{</span><span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="si">}</span><span class="s2"> detected.&quot;</span><span class="p">)</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">gpu_type</span> <span class="o">=</span> <span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span>
                                <span class="k">break</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;JAX GPU not available.&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;JAX GPU not available.&quot;</span><span class="p">)</span>
                            <span class="k">return</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">jd</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">cpu_device_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CPU&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">]</span>  
                        <span class="k">for</span> <span class="n">cpu_device_name</span> <span class="ow">in</span> <span class="n">cpu_device_names</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">cpu_device_name</span> <span class="ow">in</span> <span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JAX CPU: </span><span class="si">{</span><span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="si">}</span><span class="s2"> detected.&quot;</span><span class="p">)</span>
                                <span class="k">break</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;JAX CPU not available.&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;No JAX CPU available.&quot;</span><span class="p">)</span>
                        <span class="k">return</span>
        <span class="k">if</span> <span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;pt&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">torch</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_pytorch</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pt_version</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Pytorch not available.&quot;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_pytorch</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;tpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="n">tpu_env</span><span class="o">=</span><span class="kc">False</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;COLAB_TPU_ADDR&#39;</span><span class="p">]</span>
                        <span class="n">tpu_env</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Pytorch TPU instance not detected.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">tpu_env</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="kn">import</span> <span class="nn">torch</span>
                            <span class="k">if</span> <span class="s1">&#39;1.9.&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Pytorch version probably not supported with TPUs. Try (as of 12/2021): &quot;</span><span class="p">)</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;!pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl&quot;</span><span class="p">)</span>
                            <span class="kn">import</span> <span class="nn">torch_xla.core.xla_model</span> <span class="k">as</span> <span class="nn">xm</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Pytorch TPU detected.&quot;</span><span class="p">)</span>
                        <span class="k">except</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Pytorch TPU would be available, but failed to</span><span class="se">\</span>
<span class="s2">                                    import torch_xla.core.xla_model.&quot;</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                                <span class="k">return</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="kn">import</span> <span class="nn">torch.cuda</span>
                        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">gpu_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pytorch GPU </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu_type</span><span class="si">}</span><span class="s2"> detected.&quot;</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Pytorch GPU not available.&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Pytorch GPU not available.&quot;</span><span class="p">)</span>
                            <span class="k">return</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span> <span class="ow">or</span> <span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Pytorch CPU detected.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;No Pytorch CPU accelerator available.&quot;</span><span class="p">)</span>
                    <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flush_timer</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flush_timeout</span> <span class="o">=</span> <span class="mi">180</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_osenv</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_notebook_type</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">desc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">desc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_osenv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">os_type</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">os_type</span> <span class="o">=</span> <span class="n">os_type</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="o">+</span><span class="n">os_type</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">py_version</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="s1">&#39;conda&#39;</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_conda</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_conda</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_check_notebook_type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Internal function, use :func:`describe` instead</span>

<span class="sd">        Note: for colab notebooks and tensorflow environemts, this function</span>
<span class="sd">        will load tensorboard.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;IPKernelApp&#39;</span> <span class="ow">in</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;You are on a Jupyter instance.&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;You are not on a Jupyter instance.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span> <span class="c1"># Colab instance?</span>
                <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;load_ext&#39;</span><span class="p">,</span> <span class="s1">&#39;tensorboard&#39;</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;tensorflow_version&#39;</span><span class="p">,</span> <span class="s1">&#39;2.x&#39;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">pass</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;You are on a Colab instance.&quot;</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span> <span class="c1"># Not? ignore.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;You are not on a Colab instance, so no Google Drive access is possible.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span>

<div class="viewcode-block" id="MLEnv.describe_osenv"><a class="viewcode-back" href="../index.html#env_tools.MLEnv.describe_osenv">[docs]</a>    <span class="k">def</span> <span class="nf">describe_osenv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;OS: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">os_type</span><span class="si">}</span><span class="s2">, Python: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">py_version</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_conda</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">+=</span> <span class="s2">&quot; (Conda)&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span><span class="p">:</span>
                <span class="n">desc</span> <span class="o">+=</span> <span class="s2">&quot;, Colab Jupyter Notebook&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">desc</span> <span class="o">+=</span> <span class="s2">&quot;, Jupyter Notebook&quot;</span>
        <span class="k">return</span> <span class="n">desc</span></div>

<div class="viewcode-block" id="MLEnv.describe_mlenv"><a class="viewcode-back" href="../index.html#env_tools.MLEnv.describe_mlenv">[docs]</a>    <span class="k">def</span> <span class="nf">describe_mlenv</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Tensorflow: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_version</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_pytorch</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Pytorch: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pt_version</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_jax</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;JAX: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">jax_version</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">=</span> <span class="s2">&quot;(no-ml-platform) &quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;, TPU: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tpu_type</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;, GPU: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">gpu_type</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">desc</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;, CPU&quot;</span>
        <span class="k">return</span> <span class="n">desc</span></div>

<div class="viewcode-block" id="MLEnv.describe"><a class="viewcode-back" href="../index.html#env_tools.MLEnv.describe">[docs]</a>    <span class="k">def</span> <span class="nf">describe</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Prints a description of the machine environment.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: description of the machine environment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">describe_osenv</span><span class="p">())</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">describe_mlenv</span><span class="p">())</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">describe_osenv</span><span class="p">()</span><span class="o">+</span><span class="s2">&quot; &quot;</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">describe_mlenv</span><span class="p">()</span></div>

<div class="viewcode-block" id="MLEnv.mount_gdrive"><a class="viewcode-back" href="../index.html#env_tools.MLEnv.mount_gdrive">[docs]</a>    <span class="k">def</span> <span class="nf">mount_gdrive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mount_point</span><span class="o">=</span><span class="s2">&quot;/content/drive&quot;</span><span class="p">,</span> <span class="n">root_path</span><span class="o">=</span><span class="s2">&quot;/content/drive/My Drive&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;You will now be asked to authenticate Google Drive access in order to store training data (cache) and model state.&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Changes will only happen within Google Drive directory `My Drive/Colab Notebooks/ALU_Net`.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">root_path</span><span class="p">):</span>
                <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="n">mount_point</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">root_path</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">root_path</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Something went wrong with Google Drive access. Cannot save model to </span><span class="si">{</span><span class="n">root_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">root_path</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;You are not on a Colab instance, so no Google Drive access is possible.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="MLEnv.init_paths"><a class="viewcode-back" href="../index.html#env_tools.MLEnv.init_paths">[docs]</a>    <span class="k">def</span> <span class="nf">init_paths</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model_variant</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="o">=</span><span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="o">=</span><span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_path</span> <span class="o">=</span> <span class="s2">&quot;./logs&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mount_gdrive</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="o">=</span><span class="s1">&#39;.&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Root path: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Colab Notebooks/</span><span class="si">{</span><span class="n">project_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root_path</span>
            <span class="k">if</span> <span class="n">model_variant</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_weights.h5&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">model_variant</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">model_variant</span><span class="si">}</span><span class="s2">_weights.h5&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model save-path: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weights save-path: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data cache path </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_path</span></div></div>

</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">ml-indie-tools 0.0.4 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">env_tools</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, dsc.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.3.2.
    </div>
  </body>
</html>