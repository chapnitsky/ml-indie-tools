

<!doctype html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>env_tools &#8212; ml-indie-tools 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/bizstyle.css" />
    
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <!--[if lt IE 9]>
    <script src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">ml-indie-tools 0.0.1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">env_tools</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for env_tools</h1><div class="highlight"><pre>
<span></span><span class="sd">&#39;&#39;&#39;Setup tools to configure ML environment for Tensorflow, Pytorch or JAX and optional notebook/colab environment&#39;&#39;&#39;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">shutil</span>

<div class="viewcode-block" id="MLEnv"><a class="viewcode-back" href="../index.html#env_tools.MLEnv">[docs]</a><span class="k">class</span> <span class="nc">MLEnv</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot; Initialize deep learning platform. Known platforms are: &#39;tf&#39;, &#39;pt&#39;,</span>
<span class="sd">    &#39;jax&#39;, known accelerators are: &#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39;, or &#39;fastest&#39; &quot;&quot;&quot;</span>
<div class="viewcode-block" id="MLEnv.__init__"><a class="viewcode-back" href="../index.html#env_tools.MLEnv.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">platform</span><span class="o">=</span><span class="s1">&#39;tf&#39;</span><span class="p">,</span> <span class="n">accelerator</span><span class="o">=</span><span class="s1">&#39;fastest&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initialize platform. Known platforms are: &#39;tf&#39; (tensorflow), &#39;pt&#39;</span>
<span class="sd">        (pytorch), and &#39;jax&#39;, known</span>
<span class="sd">        accelerators are: &#39;fastest&#39; (pick best available hardware), &#39;cpu&#39;, &#39;gpu&#39;, &#39;tpu&#39; &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">known_platforms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;tf&#39;</span><span class="p">,</span> <span class="s1">&#39;pt&#39;</span><span class="p">,</span> <span class="s1">&#39;jax&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">known_accelerators</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="s1">&#39;gpu&#39;</span><span class="p">,</span> <span class="s1">&#39;tpu&#39;</span><span class="p">,</span> <span class="s1">&#39;fastest&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">platform</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">known_platforms</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Platform </span><span class="si">{</span><span class="n">platform</span><span class="si">}</span><span class="s2"> is not known, please check spelling.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="n">accelerator</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">known_accelerators</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accelerator </span><span class="si">{</span><span class="n">accelerator</span><span class="si">}</span><span class="s2"> is not known, please check spelling.&quot;</span><span class="p">)</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">platform</span> <span class="o">=</span> <span class="n">platform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">=</span> <span class="n">accelerator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_pytorch</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_jax</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensorflow not available: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="c1"># %tensorflow_version 2.x</span>
            <span class="c1"># import tensorflow as tf</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensorflow version: &quot;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;tpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">tpu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">TPUClusterResolver</span><span class="p">()</span>  <span class="c1"># TPU detection</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running on TPU &#39;</span><span class="p">,</span> <span class="n">tpu</span><span class="o">.</span><span class="n">cluster_spec</span><span class="p">()</span><span class="o">.</span><span class="n">as_dict</span><span class="p">()[</span><span class="s1">&#39;worker&#39;</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                    <span class="n">tpu</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No TPU available&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>    
                    <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental_connect_to_cluster</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
                    <span class="n">tf</span><span class="o">.</span><span class="n">tpu</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">initialize_tpu_system</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">tpu_strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TPU strategy available&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU not available: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU available&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No GPU or TPU available, this is going to be very slow!&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;jax&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">jax</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_jax</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jax not available&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_jax</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;tpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="kn">import</span> <span class="nn">jax.tools.colab_tpu</span>
                        <span class="n">jax</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">colab_tpu</span><span class="o">.</span><span class="n">setup_tpu</span><span class="p">()</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;JAX TPU detected.&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;JAX TPU not detected.&quot;</span><span class="p">)</span>
                                <span class="k">return</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">jd</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">gpu_device_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;GTX&#39;</span><span class="p">,</span> <span class="s1">&#39;Nvidia&#39;</span><span class="p">]</span>  <span class="c1"># who knows?</span>
                        <span class="k">for</span> <span class="n">gpu_device_name</span> <span class="ow">in</span> <span class="n">gpu_device_names</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">gpu_device_name</span> <span class="ow">in</span> <span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JAX GPU: </span><span class="si">{</span><span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="si">}</span><span class="s2"> detected.&quot;</span><span class="p">)</span>
                                <span class="k">break</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;JAX GPU not available.&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;JAX GPU not available.&quot;</span><span class="p">)</span>
                                <span class="k">return</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">jd</span><span class="o">=</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="n">cpu_device_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CPU&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">]</span>  
                        <span class="k">for</span> <span class="n">cpu_device_name</span> <span class="ow">in</span> <span class="n">cpu_device_names</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">cpu_device_name</span> <span class="ow">in</span> <span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;JAX CPU: </span><span class="si">{</span><span class="n">jd</span><span class="o">.</span><span class="n">device_kind</span><span class="si">}</span><span class="s2"> detected.&quot;</span><span class="p">)</span>
                                <span class="k">break</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;JAX CPU not available.&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No JAX CPU available.&quot;</span><span class="p">)</span>
                        <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;pt&#39;</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">torch</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_pytorch</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch not available.&quot;</span><span class="p">)</span>
                <span class="k">return</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_pytorch</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;tpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="n">tpu_env</span><span class="o">=</span><span class="kc">False</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;COLAB_TPU_ADDR&#39;</span><span class="p">]</span>
                        <span class="n">tpu_env</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch TPU instance not detected.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">tpu_env</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="kn">import</span> <span class="nn">torch</span>
                            <span class="k">if</span> <span class="s1">&#39;1.9.&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span> <span class="ow">and</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch version probably not supported with TPUs. Try (as of 12/2021): &quot;</span><span class="p">)</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;!pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl&quot;</span><span class="p">)</span>
                            <span class="kn">import</span> <span class="nn">torch_xla.core.xla_model</span> <span class="k">as</span> <span class="nn">xm</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch TPU detected.&quot;</span><span class="p">)</span>
                        <span class="k">except</span><span class="p">:</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch TPU would be available, but failed to</span><span class="se">\</span>
<span class="s2">                                    import torch_xla.core.xla_model.&quot;</span><span class="p">)</span>
                            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                                <span class="k">return</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;gpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="kn">import</span> <span class="nn">torch.cuda</span>
                        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">True</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch GPU detected.&quot;</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch GPU not available.&quot;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">!=</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch GPU not available.&quot;</span><span class="p">)</span>
                                <span class="k">return</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span> <span class="o">==</span> <span class="s1">&#39;fastest&#39;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_cpu</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pytorch CPU detected.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No Pytorch CPU accelerator available.&quot;</span><span class="p">)</span>
                    <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flush_timer</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flush_timeout</span> <span class="o">=</span> <span class="mi">180</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_notebook_type</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span></div>
        <span class="c1"># self.check_hardware(verbose=verbose)</span>

    <span class="k">def</span> <span class="nf">check_notebook_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;IPKernelApp&#39;</span> <span class="ow">in</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are on a Jupyter instance.&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">NameError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are not on a Jupyter instance.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span> <span class="c1"># Colab instance?</span>
                <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;load_ext&#39;</span><span class="p">,</span> <span class="s1">&#39;tensorboard&#39;</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;tensorflow_version&#39;</span><span class="p">,</span> <span class="s1">&#39;2.x&#39;</span><span class="p">)</span>
                    <span class="k">except</span><span class="p">:</span>
                        <span class="k">pass</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are on a Colab instance.&quot;</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span> <span class="c1"># Not? ignore.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are not on a Colab instance, so no Google Drive access is possible.&quot;</span><span class="p">)</span>
                <span class="k">pass</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_notebook</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span>

    <span class="c1"># Hardware check:</span>
    <span class="k">def</span> <span class="nf">check_hardware</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tpu_is_init</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tpu_address</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tensorflow</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">tpu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">cluster_resolver</span><span class="o">.</span><span class="n">TPUClusterResolver</span><span class="p">()</span>  <span class="c1"># TPU detection</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running on TPU &#39;</span><span class="p">,</span> <span class="n">tpu</span><span class="o">.</span><span class="n">cluster_spec</span><span class="p">()</span><span class="o">.</span><span class="n">as_dict</span><span class="p">()[</span><span class="s1">&#39;worker&#39;</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">tpu_profile_service_address</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;COLAB_TPU_ADDR&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;8470&#39;</span><span class="p">,</span> <span class="s1">&#39;8466&#39;</span><span class="p">)</span>
                    <span class="n">state</span><span class="o">=</span><span class="n">profiler_client</span><span class="o">.</span><span class="n">monitor</span><span class="p">(</span><span class="n">tpu_profile_service_address</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
                    <span class="k">if</span> <span class="s1">&#39;TPU v2&#39;</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: you got old TPU v2 which is limited to 8GB Ram.&quot;</span><span class="p">)</span>

                <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No TPU available&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">for</span> <span class="n">hw</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="s2">&quot;GPU&quot;</span><span class="p">,</span> <span class="s2">&quot;TPU&quot;</span><span class="p">]:</span>
                <span class="n">hw_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="n">hw</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hw_list</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">hw</span><span class="o">==</span><span class="s1">&#39;TPU&#39;</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span><span class="o">=</span><span class="kc">True</span>
                    <span class="k">if</span> <span class="n">hw</span><span class="o">==</span><span class="s1">&#39;GPU&#39;</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span><span class="o">=</span><span class="kc">True</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">hw</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">hw_list</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">get_device_details</span><span class="p">(</span><span class="n">hw_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> 

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_gpu</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: You have neither TPU nor GPU, this is going to be very slow!&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU available&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">disable_eager_execution</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TPU: eager execution disabled!&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensorflow not available, so no hardware check (yet).&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mount_gdrive</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mount_point</span><span class="o">=</span><span class="s2">&quot;/content/drive&quot;</span><span class="p">,</span> <span class="n">root_path</span><span class="o">=</span><span class="s2">&quot;/content/drive/My Drive&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You will now be asked to authenticate Google Drive access in order to store training data (cache) and model state.&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Changes will only happen within Google Drive directory `My Drive/Colab Notebooks/ALU_Net`.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">root_path</span><span class="p">):</span>
                <span class="c1"># drive.flush_and_unmount()</span>
                <span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="n">mount_point</span><span class="p">)</span> <span class="c1">#, force_remount=True)</span>
                <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">root_path</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">root_path</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Something went wrong with Google Drive access. Cannot save model to </span><span class="si">{</span><span class="n">root_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="n">root_path</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You are not on a Colab instance, so no Google Drive access is possible.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">init_paths</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">project_name</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">model_variant</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log_to_gdrive</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="o">=</span><span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="o">=</span><span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_path</span> <span class="o">=</span> <span class="s2">&quot;./logs&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_to_gdrive</span> <span class="o">=</span> <span class="n">log_to_gdrive</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mount_gdrive</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="o">=</span><span class="s1">&#39;.&#39;</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Root path: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_colab</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Colab Notebooks/</span><span class="si">{</span><span class="n">project_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">log_to_gdrive</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;Colab Notebooks/</span><span class="si">{</span><span class="n">project_name</span><span class="si">}</span><span class="s2">/logs&quot;</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Logs will be mirrored to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="si">}</span><span class="s2">, they can be used with a remote Tensorboard instance.&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">root_path</span>
            <span class="k">if</span> <span class="n">model_variant</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_weights.h5&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">model_variant</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">model_variant</span><span class="si">}</span><span class="s2">_weights.h5&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_tpu</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model save-path: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weights save-path: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data cache path </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">root_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights_file</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_path</span>

    <span class="k">def</span> <span class="nf">gdrive_log_mirror</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># copy directory self.log_path to self.log_mirror_path</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_to_gdrive</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">4</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span><span class="o">==</span><span class="s1">&#39;/logs&#39;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Removing old log files from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Staring tree-copy of files from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="si">}</span><span class="s2">. [This can be astonishingly slow!]&quot;</span><span class="p">)</span>
                    <span class="n">shutil</span><span class="o">.</span><span class="n">copytree</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="p">)</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tensorboard data mirrored to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Log-mirror path is not valid: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">log_mirror_path</span><span class="si">}</span><span class="s2">, it needs to end with &#39;/logs&#39; as sanity-check&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">epoch_time_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">log</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_to_gdrive</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">flush_timer</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">flush_timeout</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">flush_timer</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">gdrive_log_mirror</span><span class="p">()</span></div>

</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="../index.html">ml-indie-tools 0.0.1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">env_tools</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, dsc.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.3.2.
    </div>
  </body>
</html>